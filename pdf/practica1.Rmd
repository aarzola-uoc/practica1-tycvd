---
title: 'Práctica 1: Web scraping'
author: "Miguel Santos Pérez  y Alejandro Arzola García"
date: "14 de abril de 2020"
output:
  word_document:
    toc: yes
    toc_depth: '2'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '2'
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
subtitle: UOC - Tipología y ciclo de vida de los datos
toc-title: Índice
---

\newpage
# Contexto

El auge del valor del dato y su aplicación a cualquier ámbito de la sociedad es claro desde su explosión unos años atrás. En este sentido, cada vez más tecnologías basadas en el poder del dato se emplean con eficiencia en distintos deportes como el fútbol, para diversas tareas tales como el fichaje de jugadores, campañas de marketing o estrategias de partidos. Técnicas similares son aplicadas al tenis.

En cuanto al deporte del que nos ocuparemos en este trabajo, concretamente el baloncesto vivimos en un mundo bipolar. Mientras en América, las poderosas franquicias NBA cada vez lo utilizan más en su día a día con grandes equipos de Data Scientist, en Europa el gasto en la explotación del dato se mantiene en segundo plano. Así pues, la inspiración de este estudio es desarrollar el webscrapping sobre el conjunto de datos de baloncesto en Europa, como primera aproximación para luego utilizar estos datos y buscarles su valor. En este primer trabajo, por tanto, se tratará de acceder a los partidos de Euroliga y almacernarlos en datasets que sean analizables.

Todos estos resultados se encuentran en la web oficial de la competición, www.euroleague.net

![](C:/Users/USER-PC/Desktop/logo.PNG) 


# Componentes del grupo

* Miguel Santos Pérez (miguel8santos@uoc.edu)
* Alejandro Arzola García (aarzola@uoc.edu)

# Repositorio Github

Para la realización de esta práctica se ha creado un repositorio en _GitHub_ para trabajar de manera colaborativa y tener un control de versiones sobre el código fuente. Se puede acceder a este repositorio a través del siguiente enlace:

* https://github.com/aarzola-uoc/practica1-tycvd

# Título para el dataset

Euroliga 2019-2020. Marcadores y estadísticas por partido.

# Descripción del dataset

Se propone para este trabajo la obtención de dos datasets, el primero con todos los marcadores, partidos y enlaces a estadísticas y, el segundo, con el detalle de las propias estadísticas para su posterior análisis.

# Representación gráfica

El proyecto representa, para cada partido, en un dataset los siguientes datos.  
El primer dataset, recoge los resultados y es el siguiente:


![Dataset 1](C:/Users/USER-PC/Desktop/resultado.png) 
  
  
El segundo dataset, recoge las estadísticas individuales dentro de un partido y representa:

![Dataset 2](C:/Users/USER-PC/Desktop/estadistica1.png)
![Dataset 2](C:/Users/USER-PC/Desktop/estadistica2.png)

# Contenido

Así, definimos la estructura de los dataset como:

- **Euroleague_Scoreboards**: Dicho dataset recoge los resultados por partido y se compone de siete campos:
  - MatchId: identificador único del partido.
  - Date: fecha del partido.
  - HomeTeam: nombre del equipo local.
  - HomeScore: puntos anotados por el equipo local
  - VisitingTeam: nombre del equipo visitante.
  - VisitingScore: puntos anotados por el equipo visitante.
  - Link: link de estadísticas.  
  
- **Euroleague_Stats_per_Game**: Dicho dataset recoge las estadísticas a nivel jugador por partido y se compone de:
  - MatchId: identificador único de partido.
  - Team: equipo al que pertenece el jugador.
  - PlayerNumber: número del jugador.
  - PlayerName: nombre del jugador.
  - Min: minutos jugados.
  - Pts: puntos anotados.
  - 2FG: tiros de dos (metidos-anotados).
  - 3FG: tiros de tres (metidos-anotados).
  - FT: tiros libres (metidos-anotados).
  - O: rebotes ofensivos.
  - D: rebotes defensivos.
  - T: rebotes totales.
  - As: asistencias.
  - St: recuperaciones.
  - To: pérdidas.
  - Fv: tapones a favor.
  - Ag: tapones en contra.
  - Cm: faltas cometidas.
  - Rv: faltas recibidas.
  - PIR: valoración del jugador. 

El periodo de recolección de los datos es esta temporada, desde los partidos qeu empezaron el 3 de octubre hasta los terminados el 5 de marzo.
  
# Publicación del dataset

Se han publicados los dos _datasets_ obtenidos en el repositorio web **Zenodo** y se pueden acceder a través del siguiente enlace:

* https://zenodo.org/record/3740661#.XoouwVNKgnU

El DOI (_Digital Object Identifier_) asignado ha sido el siguiente:

* 10.5281/zenodo.3740661

# Agradecimientos

Los datos, recogidos de la web oficial de la competición, son propiedad de © Euroleague Ventures SA. Para ello se ha hecho uso del lenguaje de programación Python y de técnicas de WebScrapping para extraer la información alojada en las páginas.

# Inspiración

De la mano de lo explicado en la contextualización, se hace interesante la disponibilidad de los datos de una manera sencilla de analizar como primer paso de cara a un posterior uso en el planteamiento de los partidos o de las semanas de entrenamiento. 
La mayor ambición es la realización de un análisis profundo que permita a los equipos disponer de una herramienta que les proporcione en los datos un valor añadido. A partir de las estadísticas recogidas por Euroliga, se podrían crear nuevas estadísticas más precisas que recojan otro tipo de datos en función de los ya existentes.

# Licencia

La licencia escogida para la publicación de este conjunto de datos ha sido **CC BY-SA 4.0 License**. A continuación detallamos los motivos principales qeu han llevado a escoger esta licencia:
- *Se debe proveer proveer el nombre del creador del conjunto de datos generado, indicando los cambios que se han realizado*. De esta manera, se reconoce el trabajo ajeno y en qué medida se han realizado aportaciones en realidad con el trabajo original.
- *Se permite un uso comercial*. Esto haría que incrementen las probabilidades de que una empresa utilice los datos generados y realicen trabajos de calidad que reporten cierto reconocimiento a los autores.
- *Las contribuciones realizadas a posteriori sobre el trabajo publicado bajo esta licencia deberán distribuirse bajo la misma*. Eso hace que el trabajo del autor original continúe distribuyéndose bajo los términos que él mismo planteó.

# Contribuciones al trabajo

**Contribuciones**              |  **Firma**                    | 
--------------------------------|:-----------------------------:|
Investigación previa            | MSP, AAG
Redacción de las respuestas     | MSP, AAG
Creación del repositorio GitHub | MSP, AAG
Desarrollo código               | MSP, AAG
Publicación de los datasets     | MSP, AAG


# Código

El proceso de extracciÃ³n ha sido bastante sencillo. En primer lugar accedimos al fichero _robots.txt_ para la web de la Euroliga, disponible en el siguiente enlace:

* https://www.euroleague.net/robots.txt

El contenido de este fichero se muestra a continuaciÃ³n:

```
User-agent: Sosospider
Disallow: /

User-agent: Yandex
Disallow: /

User-agent: Baiduspider
Disallow: /

User-agent: *
Crawl-delay: 15
```

Podemos ver que para las herramientas `Sosospider`, `Yandex` y `Baiduspider` está bloqueado todo el contenido, pero dado que no usamos ninguna de ellas no nos suponía un problema. La última instrucciónn indica que para cualquier _"user-agent"_  se aplica la política `Crawl-delay` con un valor de 15 segundos.

Ninguna de estas restricciones afectaban al desarrollo de nuestro código _Python_ por lo que comenzamos con su desarrollo. Importamos la librería _BeautifulSoup_ y probamos a obtener todo el código HTML de la página. Después de revisar que los datos que queríamos _scrapear_ se encontraban en el HTML ya comenzamos a utilizar las funciones de esta librería como `find()` o `find_all()`. Cuando ya teníamos todos los datos de los partidos, decidimos obtener el segundo dataset para las estadísticas individuales de los jugadores. Finalmente realizamos una refactorización del código para pasar de un paradigma de programación estructurada a un paradigma de programación orientada a objetos con la creación de nuestra propia clase `EuroligaScraper`.